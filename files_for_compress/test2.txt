В понедельник 25 ноября южнокорейский мастер игры го 9 дана Ли Седоль рассказал в интервью, что он больше не будет участвовать в профессиональных соревнованиях. В качестве главной причины для завершения своей спортивной карьеры Седоль называет появление систем компьютерного го, которые играют лучше любого из людей. Даже если стать лучшим, всё равно будет нечто, что никогда не превзойти, говорит Седоль.

За пределами кругов поклонников го Ли Седоль получил известность благодаря играм против системы AlphaGo, разработанной компанией Google DeepMind. Го из-за своих особенностей долгое время не удавалось оптимизировать так, чтобы компьютеры могли обыгрывать людей. В 2016 году британская DeepMind провела матч из пяти партий, в котором один из лучших из людей — Седоль — проиграл до этого малоизвестной программе.

С той игры прошли три года. За это время улучшенная версия AlphaGo обыграла другого человека-чемпиона, DeepMind выпустила несколько научных работ по нейросети и рассказала о системе AlphaZero, а потом, кажется, потеряла любой интерес к проекту. Лишь сейчас Седоль решил оставить го. Есть ли для его решения другие причины?

О развитии систем компьютерного го и причинах поступка Ли Седоля мы поговорили с 7-кратным чемпионом Европы по го, действующим чемпионом России и членом президиума Российской федерации го Александром Динерштейном.


В январе 2016 года обычно немногословная DeepMind разразилась научной работой, пресс-релизом и видеороликом. Впервые в мире был создан искусственный интеллект, который способен обыграть человека-чемпиона в азиатскую игру го.

На тот момент го считалась одной из последних настольных логических игр, в которую люди могли играть лучше любого компьютерного алгоритма. Как и шахматы, го — игра с совершенной информацией, то есть игроки знают обо всех ходах, которые ранее совершили другие игроки. Но если ни один гроссмейстер уже с 2005 года не может обыграть лучшие из шахматных программ, то компьютерные алгоритмы в го на тот момент играли на уровне любителей.

Два игрока расставляют на доске определённого размера камни чёрного или белого цвета. Цель игры — отгородить на доске камнями своего цвета территорию большего, чем оппонент, размера. Многие из ходов го основаны на интуиции, которую сложно описать алгоритмом.

Вычислительная сложность го связана с большим числом возможных позиций и корректных ходов из них. Задача поиска исхода игры связана с вычислениями функции оптимального значения в дереве поиска, в котором находятся bd ходов. В го количество корректных ходов b ≈ 250, длина игры d ≈ 150. На стандартной доске 19×19 линий возможных позиций в гугол (10100) раз больше, чем атомов во Вселенной.

Программы до AlphaGo полагались на поиск по дереву Монте-Карло для оценки ценности каждого состояния в дереве поиска. При создании AlphaGo к этому алгоритму добавили глубинные свёрточные нейросети. Нейросети обучили с помощью 160 тысяч матчей с сервера игры го через Интернет KGS с 29,4 млн позиций. Дополнительно AlphaGo играла пять тысяч партий против самой себя.

Полученная программа в лабораторных условиях превзошла любые коммерчески доступные продукты и открытые проекты компьютерного го. AlphaGo выиграла 499 матчей из 500 против игроков-программ. Алгоритм нужно было опробовать на человеке, поэтому против программы пригласили играть трёхкратного чемпиона Европы Фань Хуэя. В октябре 2015 года в лондонском офисе Google Хуэй проиграл алгоритму пять из пяти игр.

На тот момент это не было окончательным поражением. Конечно, Хуэй — хороший игрок, но для чемпионатов Европы. Наивысшим уровнем обладают мастера го из основного очага распространения игры — Азии. Поэтому для закрепления результата Google объявила о намерении провести в марте 2016 года в Сеуле матч AlphaGo против Ли Седоля, который на тот момент считался лучшим игроком десятилетия.

Из пяти партий серии Седоль выиграл одну. Лишь в четвёртой игре — когда три победы AlphaGo уже определили исход матча — ИИ признал поражение.


Программисты DeepMind почему-то не предусмотрели драматичного сообщения на случай поражения программы.

DeepMind могла бы удовлетвориться счётом 4:1. Но внутри компании продолжали работать. К июню 2016 года сформировались планы дать AlphaGo поиграть против другого чемпиона го — китайца Кэ Цзе. Матч назначили на май 2017.

С 29 декабря 2016 года на корейском сервере Tygem и китайском Fox начал регулярно играть необычно сильный игрок под именем Magister или Master. Игрок выиграл 60 партий у профессионалов высокого уровня. За победу против незнакомца даже назначали награду. 4 января глава DeepMind Демис Хассабис признался, что этот игрок — новая версия AlphaGo.

AlphaGo Fan играл против Фань Хуэя, игравший против Седоля вариант назвали AlphaGo Lee, в Интернете и против Кэ Цзе играл AlphaGo Master. Каждая из версий требовала для запуска всё меньше и меньше оборудования, но играла сильнее предшественника. В DeepMind оценили, что для игры Fan c Lee на равных первому пришлось бы дать три камня форы, Master оказался сильнее Lee ещё на три камня. Неудивительно, что на Future of Go Summit весной 2017 года Кэ Цзе проиграл новой версии AlphaGo все три игры.

Google не выпустила исходные коды AlphaGo и не продаёт программу. Вероятно, эти игры — лишь демонстрация технологического могущества компании. AlphaGo обязана своим успехом аппаратному вычислительному ускорителю TPU собственной разработки Google. По уменьшению количества необходимых модулей легко отследить увеличение эффективности. Партии игры Фань Хуэя обсчитывали 176 видеоускорителей, против Седоля играли 50 плат TPU, против Цзэ выставили всего одну.


Вычислительный кластер, который обыграл Ли Седоля.

DeepMind демонстрировала успехи программной разработки. Для обучения трёх первых версий AlphaGo правилам игры требовались сотни тысяч партий людей, в алгоритм заложены некоторые вручную заданные функции. Версия AlphaGo Zero училась играть полностью самостоятельно, а нейросети политики и ценности в ней объединены в одну. За 3 дня самообучения Zero превзошла Lee, за 40 дней — Master. Менее чем за полтора месяца алгоритм с нуля научился играть лучше людей в игру, история которой насчитывает тысячелетия человеческого опыта.

DeepMind так никогда и не выпустила исходные коды AlphaGo. Программу невозможно нигде приобрести или сыграть против неё, с весны 2017 она не играет против людей. Для желающих перенять мудрость AlphaGo есть лишь обнародованные партии продукта. Возможно, Google не хочет ассоциировать свою деятельность с системами компьютерного го.

Зато другие быстро переняли знания из опубликованных данных. Похожая масштабом и охватом деятельности на Google китайская Tencent начала создавать собственный алгоритм почти сразу после самой первой публикации научной работы по матчу Фань Хуэя. За год продукт под названием Fine Art сильно прокачали. Уже в 2017 году на сервере FGS алгоритм впервые набрал 10 дан. На чемпионате компьютерного го Computer Go UEC Cup в марте 2017 года программа Fine Art превзошла 29 алгоритмов и получила право сыграть против чемпиона-человека и одержала победу. За схожесть с программой DeepMind алгоритм Fine Art прозвали «китайский AlphaGo».

AlphaGo Zero и AlphaZero учатся не на основе партий игроков-людей, а в играх против самих себя. Сторонние разработчики пытались повторить и эти программы. Проект с открытым исходным кодом Leela Zero откровенно говорит, что пытается воссоздать описанное в научной работе DeepMind.

Собственную реализацию компьютерного го создал и Facebook. В мае 2018 компания открыла исходные коды проекта ELF OpenGo. Натренированный на 2000 видеоускорителях алгоритм запускается на одной видеокарте. Он играет сильнее четырёх из тридцати лучших игроков го в мире.

Facebook также не скрывала, что работает на основе исследований DeepMind. Об этом говорит не только текст, но и даже названия научных работ: «ELF OpenGo: An Analysis and Open Reimplementation of AlphaZero». На основании ELF OpenGo Facebook создала инструмент для анализа партий игроков-людей. На сегодняшний день эта программа остаётся одной из сильнейших среди общедоступных, её анализируют собственные партии многие профессиональные игроки.

Южнокорейская компания NHN Entertainment также переняла опыт DeepMind. Разработка программы HanDol начались в 2016 году в период общей заинтересованности в AlphaGo. Версия 1.0 вышла в декабре 2017 года, её уровень игры был сравним с уровнем игрока 9 дана. HanDol 1.0 требовала обучения на записях игр людей, HanDol 2.0 переняла идею тренировок только на играх против самой себя. NHN Entertainment утверждает, что HanDol Lee играет не хуже AlphaGo Lee, игроки говорят, что алгоритм чуть хуже AlphaGo Master.

HanDol также зарекомендовала себя как система компьютерного го сильнее людей. К концу января 2019 года программа одержала победу над пятью лучшими в Южной Корее мастерами 9 дана. NHN Entertainment предлагает HanDol как услугу тренировок игроков и анализа партий.


Через три года после публикации первой научной работы DeepMind об AlphaGo от превосходства людей в го не осталось и следа. Сила компьютерных систем в го не вызывает вопросов, к ним уже обращаются за советами, у них учатся. Несколько научных работ и десятки партий без какого-либо доступа к программе — но по ней снят даже документальный фильм AlphaGo (доступен в пиратском переводе на русский язык).

Тем не менее с матча Ли Седоль — AlphaGo прошло уже больше трёх лет. Почему Седоль решил уйти из го только сейчас?

На наши вопросы ответил 7-кратный чемпион Европы и действующий чемпион России по го Александр Динерштейн.

В 36 лет Ли Седоль прерывает свою легендарную 24-летнюю карьеру. Случается ли в го такое, что многие профессионалы уходят из игры на рубеже 35—40 лет? Каков типичный путь в жизни мастера го 9 дана?
